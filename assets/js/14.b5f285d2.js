(window.webpackJsonp=window.webpackJsonp||[]).push([[14],{303:function(t,r,a){t.exports=a.p+"assets/img/pytorchLogo.6c14bf95.jpeg"},353:function(t,r,a){"use strict";a.r(r);var s=a(5),o=Object(s.a)({},(function(){var t=this,r=t._self._c;return r("ContentSlotsDistributor",{attrs:{"slot-key":t.$parent.slotKey}},[r("p",[r("img",{attrs:{src:a(303),alt:"Pytorch Logo"}})]),t._v(" "),r("p",[t._v("Pytorch是很受欢迎一个框架，但大多数人都止步于使用Pytorch，却不想去探究Pytorch内部的具体实现。然而，这种探索的过程本身会很有趣。")]),t._v(" "),r("p",[t._v("这个系列，将会解析Pytorch的具体实现，来学习如何构建这样一个大型的项目。\n由于Pytorch也在不断更新，增加新的功能，这个系列将会从Pytorch"),r("code",[t._v("v0.3.0")]),t._v("版本开始解析。")]),t._v(" "),r("h1",{attrs:{id:"什么是pytorch"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#什么是pytorch"}},[t._v("#")]),t._v(" 什么是Pytorch")]),t._v(" "),r("p",[r("strong",[t._v("Pytorch")]),t._v("是一个开源的机器学习库，从"),r("strong",[t._v("Torch")]),t._v("发展过来，现在主要是由FAIR和开源社区进行维护。\nPytorch主要提供了两个功能：")]),t._v(" "),r("ol",[r("li",[t._v("经过GPU加速的"),r("strong",[t._v("张量")]),t._v("(Tensor)计算功能，类似Numpy。")]),t._v(" "),r("li",[t._v("搭建基于"),r("strong",[t._v("自动微分")]),t._v("(Automatic Differentiation)求解来搭建深度神经网络。")])]),t._v(" "),r("p",[t._v("Pytorch虽然是一个"),r("strong",[t._v("Python-First")]),t._v("的框架，但它并不是完全使用Python实现的，明白这一点是理解Pytorch架构的第一步。\n但是等一下，我们先回想一下什么是Python。")]),t._v(" "),r("h1",{attrs:{id:"python是什么"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#python是什么"}},[t._v("#")]),t._v(" Python是什么？")]),t._v(" "),r("p",[t._v("Python是一个编程语言，但它与C++等编译型编程语言不同，Python是"),r("strong",[t._v("解释型")]),t._v("语言。简单来说，C++需要经过编译，链接等操作变成一个"),r("strong",[t._v("可执行程序")]),t._v("，才能运行，但Python则不需要，Python需要的是一个"),r("strong",[t._v("解释器")]),t._v("，解释器读取并执行Python源代码。")]),t._v(" "),r("p",[t._v("但是解释器又是什么？")]),t._v(" "),r("p",[t._v("现在最多人使用的解释器，是"),r("a",{attrs:{href:"https://github.com/python/cpython",target:"_blank",rel:"noopener noreferrer"}},[t._v("CPython"),r("OutboundLink")],1),t._v("，这也是Python默认的解释器，可以从Python的官网上直接下载。其实从CPython这个名字可以猜出来，CPython是用C实现的解释器，除此之外，还有使用Python自己实现的"),r("a",{attrs:{href:"https://www.pypy.org",target:"_blank",rel:"noopener noreferrer"}},[t._v("PyPy"),r("OutboundLink")],1),t._v("，以及使用.Net实现的"),r("a",{attrs:{href:"https://ironpython.net",target:"_blank",rel:"noopener noreferrer"}},[t._v("IronPython"),r("OutboundLink")],1),t._v("。")]),t._v(" "),r("p",[t._v("CPython使用C语言来实现，因此可以比较容易地接入其他使用C或者C++编写的"),r("strong",[t._v("拓展")]),t._v("(Extension)。可能你也猜到了，Pytorch就是这样的"),r("strong",[t._v("拓展")]),t._v("。")]),t._v(" "),r("div",{staticClass:"language-python extra-class"},[r("pre",{pre:!0,attrs:{class:"language-python"}},[r("code",[t._v("C "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v(" Extension"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v('"torch._C"')]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              libraries"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("main_libraries"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              sources"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("main_sources"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              language"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v("'c'")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              extra_compile_args"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("main_compile_args "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" extra_compile_args"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              include_dirs"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("[")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("]")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              library_dirs"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("library_dirs"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(",")]),t._v("\n              extra_link_args"),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("=")]),t._v("extra_link_args "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" main_link_args "),r("span",{pre:!0,attrs:{class:"token operator"}},[t._v("+")]),t._v(" make_relative_rpath_args"),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v("(")]),r("span",{pre:!0,attrs:{class:"token string"}},[t._v("'lib'")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),r("span",{pre:!0,attrs:{class:"token punctuation"}},[t._v(")")]),t._v("\n")])])]),r("p",[t._v("从这段代码中可以看出来，Pytorch的主要实现，还是使用C++来完成的，并使用Python来对底层实现进行一些包装和拓展。")]),t._v(" "),r("h1",{attrs:{id:"pytorch由什么构成"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#pytorch由什么构成"}},[t._v("#")]),t._v(" Pytorch由什么构成")]),t._v(" "),r("p",[t._v("Pytorch主要提供了两个大的功能：")]),t._v(" "),r("ol",[r("li",[t._v("类似Numpy的计算，适用于不同计算性能的设备。")]),t._v(" "),r("li",[t._v("自动微分引擎，可以帮助我们计算梯度。")])]),t._v(" "),r("h2",{attrs:{id:"tensor"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#tensor"}},[t._v("#")]),t._v(" Tensor")]),t._v(" "),r("p",[t._v("Tensor一般被称作张量，可以认为就是多维数组，Tensor进行的计算，包含加减乘除之类的基本运算。为了在不同的计算设备上进行计算，Pytorch利用了一些更为底层的库，这些库是继承自"),r("a",{attrs:{href:"https://github.com/torch",target:"_blank",rel:"noopener noreferrer"}},[t._v("Torch"),r("OutboundLink")],1),t._v("的，对于不同的计算设备，比如CPU、GPU，Pytorch会利用专门为这个计算设备编写优化的计算库来计算，这些库有：")]),t._v(" "),r("ol",[r("li",[t._v("TH: Torch")]),t._v(" "),r("li",[t._v("THD: Torch Distributed")]),t._v(" "),r("li",[t._v("THNN: Torch Neural Networks")]),t._v(" "),r("li",[t._v("THS: Torch Sparse")]),t._v(" "),r("li",[t._v("THC: Torch Cuda")]),t._v(" "),r("li",[t._v("THCS: Torch Cuda Sparse")]),t._v(" "),r("li",[t._v("THCUNN: Torch CUda Neural Networks")])]),t._v(" "),r("p",[t._v("从名字上，就可以看出每一个库对应的计算设备。")]),t._v(" "),r("p",[t._v("Pytrorch建立在这些库之上，都这些不同计算设备进行抽象，并使用"),r("strong",[t._v("Tensor")]),t._v("作为统一的接口，自动根据当前的计算设备来选择对应的库，在代码中，进行了动态转发，在之后的文章中将会深入这个话题。")]),t._v(" "),r("h2",{attrs:{id:"自动微分引擎-auto-grad"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#自动微分引擎-auto-grad"}},[t._v("#")]),t._v(" 自动微分引擎 (Auto Grad)")]),t._v(" "),r("p",[t._v("在进行优化的时候，"),r("strong",[t._v("梯度下降法")]),t._v("是很常见的一种算法，在神经网络中，也采用梯度下降法及其变种来对网络的参数进行优化。")]),t._v(" "),r("p",[t._v("在利用梯度下降法进行优化的时候，必不可少的就是求出"),r("strong",[t._v("损失函数")]),t._v("关于**计算图(Computation Graph)**中每一个节点的梯度，只有求得梯度之后，才能利用不同的算法来进行优化。")]),t._v(" "),r("p",[t._v("因此"),r("strong",[t._v("自动微分")]),t._v("将会是Pytorch功能中最为关键的一环。")]),t._v(" "),r("h1",{attrs:{id:"小结"}},[r("a",{staticClass:"header-anchor",attrs:{href:"#小结"}},[t._v("#")]),t._v(" 小结")]),t._v(" "),r("p",[t._v("本文介绍了Pytorch的基础信息，包括它的结构以及主要功能。")]),t._v(" "),r("p",[t._v("这也是解读Pytorch源码系列的第一篇文章，在之后的文章中会针对Pytorch的主要功能以及实现来进行解析。")])])}),[],!1,null,null,null);r.default=o.exports}}]);