<!DOCTYPE html>
<html lang="en-US">
  <head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width,initial-scale=1">
    <title>介绍 Pytorch Lightning | Avalon</title>
    <meta name="generator" content="VuePress 1.9.7">
    <link rel="alternate" type="application/rss+xml" href="https://blog.mediosz.club/rss.xml" title="Avalon RSS Feed">
    <meta name="description" content="Pytorch在发展这么多年之后，虽然在不断添加新功能，但它的核心API一直是没有发生改变的。在编写代码的过程中，很容易发现有一部分代码是极其重复的，无论我们实现哪种网络模型，进行哪种计算，都必须要编写这些代码。

于是，我们也想到可以把这些重复的工程代码抽象出来，只编写那些特定于我们模型的代码，这 ...">
    
    <link rel="preload" href="/blog/assets/css/0.styles.14fb6a50.css" as="style"><link rel="preload" href="/blog/assets/js/app.bdc094dc.js" as="script"><link rel="preload" href="/blog/assets/js/6.e456ea1d.js" as="script"><link rel="preload" href="/blog/assets/js/3.78c3d3c8.js" as="script"><link rel="preload" href="/blog/assets/js/11.dd6dac4c.js" as="script"><link rel="preload" href="/blog/assets/js/10.70f7a74d.js" as="script"><link rel="prefetch" href="/blog/assets/js/12.2cde1e42.js"><link rel="prefetch" href="/blog/assets/js/13.9bcf6dc7.js"><link rel="prefetch" href="/blog/assets/js/14.b5f285d2.js"><link rel="prefetch" href="/blog/assets/js/15.dab0a3f7.js"><link rel="prefetch" href="/blog/assets/js/16.882af9f6.js"><link rel="prefetch" href="/blog/assets/js/17.3c6c9032.js"><link rel="prefetch" href="/blog/assets/js/18.3dc9eb95.js"><link rel="prefetch" href="/blog/assets/js/19.03ff0086.js"><link rel="prefetch" href="/blog/assets/js/20.52b478b9.js"><link rel="prefetch" href="/blog/assets/js/21.31eef441.js"><link rel="prefetch" href="/blog/assets/js/22.de0c58e9.js"><link rel="prefetch" href="/blog/assets/js/23.eb999a8b.js"><link rel="prefetch" href="/blog/assets/js/24.ccdd51aa.js"><link rel="prefetch" href="/blog/assets/js/25.d46a83f2.js"><link rel="prefetch" href="/blog/assets/js/26.2e209b64.js"><link rel="prefetch" href="/blog/assets/js/27.095bf57b.js"><link rel="prefetch" href="/blog/assets/js/28.ca0de492.js"><link rel="prefetch" href="/blog/assets/js/29.c6494259.js"><link rel="prefetch" href="/blog/assets/js/30.ec38b16b.js"><link rel="prefetch" href="/blog/assets/js/31.f57c5fbc.js"><link rel="prefetch" href="/blog/assets/js/32.c6a91f86.js"><link rel="prefetch" href="/blog/assets/js/33.34834785.js"><link rel="prefetch" href="/blog/assets/js/34.987559e0.js"><link rel="prefetch" href="/blog/assets/js/35.4e567c68.js"><link rel="prefetch" href="/blog/assets/js/36.cf11feb6.js"><link rel="prefetch" href="/blog/assets/js/37.316dd84c.js"><link rel="prefetch" href="/blog/assets/js/38.b7c1727f.js"><link rel="prefetch" href="/blog/assets/js/39.59bfb827.js"><link rel="prefetch" href="/blog/assets/js/4.4b1cad09.js"><link rel="prefetch" href="/blog/assets/js/40.3d9526e4.js"><link rel="prefetch" href="/blog/assets/js/41.ee103e02.js"><link rel="prefetch" href="/blog/assets/js/42.dce26146.js"><link rel="prefetch" href="/blog/assets/js/5.7ade25e8.js"><link rel="prefetch" href="/blog/assets/js/7.66f7834c.js"><link rel="prefetch" href="/blog/assets/js/8.1e244325.js"><link rel="prefetch" href="/blog/assets/js/9.7967ab28.js"><link rel="prefetch" href="/blog/assets/js/vuejs-paginate.17238d84.js">
    <link rel="stylesheet" href="/blog/assets/css/0.styles.14fb6a50.css">
  </head>
  <body>
    <div id="app" data-server-rendered="true"><div id="vuepress-theme-blog__global-layout"><section id="header-wrapper"><header id="header"><div class="header-wrapper"><div class="title"><a href="/blog/" class="nav-link home-link">Avalon </a></div> <div class="header-right-wrap"><ul class="nav"><li class="nav-item"><a href="/blog/" class="nav-link">中文</a></li><li class="nav-item"><a href="/blog/en/" class="nav-link">English</a></li><li class="nav-item"><a href="/blog/tag/" class="nav-link">标签</a></li></ul> <div class="search-box"><input aria-label="Search" autocomplete="off" spellcheck="false" value=""> <!----></div> <a href="/rss.xml" class="feed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg></a></div></div></header></section> <div id="mobile-header"><div class="mobile-header-bar"><div class="mobile-header-title"><a href="/blog/" class="nav-link mobile-home-link">Avalon </a> <svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-menu"><line x1="3" y1="12" x2="21" y2="12"></line><line x1="3" y1="6" x2="21" y2="6"></line><line x1="3" y1="18" x2="21" y2="18"></line></svg></div> <div class="mobile-menu-wrapper"><hr class="menu-divider"> <ul class="mobile-nav"><li class="mobile-nav-item"><a href="/blog/" class="nav-link">中文</a></li><li class="mobile-nav-item"><a href="/blog/en/" class="nav-link">English</a></li><li class="mobile-nav-item"><a href="/blog/tag/" class="nav-link">标签</a></li> <li class="mobile-nav-item"><a href="/rss.xml" class="feed"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-rss"><path d="M4 11a9 9 0 0 1 9 9"></path><path d="M4 4a16 16 0 0 1 16 16"></path><circle cx="5" cy="19" r="1"></circle></svg></a></li></ul></div></div></div> <div class="content-wrapper"><div id="vuepress-theme-blog__post-layout"><article itemscope="itemscope" itemtype="https://schema.org/BlogPosting" class="vuepress-blog-theme-content"><header><h1 itemprop="name headline" class="post-title">介绍 Pytorch Lightning</h1><div class="post-meta"><div itemprop="publisher author" itemtype="http://schema.org/Person" itemscope="itemscope" class="post-meta-author"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-navigation"><polygon points="3 11 22 2 13 21 11 13 3 11"></polygon></svg><span itemprop="name">Tricster</span><span itemprop="address">  in 南京</span></div><div class="post-meta-date"><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-clock"><circle cx="12" cy="12" r="10"></circle><polyline points="12 6 12 12 16 14"></polyline></svg><time pubdate itemprop="datePublished" datetime="2021-03-30T00:00:00.000Z">Tue Mar 30 2021</time></div><ul itemprop="keywords" class="post-meta-tags"><li class="post-tag" data-v-a940ee60><a href="/blog/tag/tech" data-v-a940ee60> tech </a></li></ul></div></header><div itemprop="articleBody" class="content__default"><p>Pytorch在发展这么多年之后，虽然在不断添加新功能，但它的核心API一直是没有发生改变的。在编写代码的过程中，很容易发现有一部分代码是极其重复的，无论我们实现哪种网络模型，进行哪种计算，都必须要编写这些代码。</p> <p>于是，我们也想到可以把这些重复的工程代码抽象出来，只编写那些特定于我们模型的代码，这也就诞生了<strong>Pytorch-Lightning</strong>。</p> <h1 id="什么是pytorch-lightning"><a href="#什么是pytorch-lightning" class="header-anchor">#</a> 什么是Pytorch-Lightning？</h1> <p>简而言之，Pytorch-Lightning是一个完全构建在Pytorch上的框架，它对Pytorch中除了模型构建之外的那部分代码进行了抽象和整合，让研究者可以专注于网络模型的搭建。</p> <blockquote><p>Spend more time on research, less on engineering.</p></blockquote> <p>除了抽象出那些比较重复的代码，Pytorch-Lightning还提供了许多很有用的功能，比如：</p> <ol><li>多节点，多GPU训练</li> <li>自动保存和读取已经训练好的权重</li> <li>对模型进行版本管理</li> <li>对训练过程进行记录</li> <li>对模型进行16bit量化</li> <li>测试模型运行的速度</li></ol> <p>如果要开发者手动实现这些功能，还是比较繁琐的，但在Pytorch-Lightning的帮助下，我们就可以在写少量代码的情况下，使用上述的功能。</p> <p>如果不使用一下Pytorch-Lightning，很难体会到它带来的便利，我们接下来看一个例子。</p> <h1 id="pytorch识别mnist"><a href="#pytorch识别mnist" class="header-anchor">#</a> Pytorch识别MNIST</h1> <p>使用Pytorch来识别MNIST数据集是很基础的任务，直接放出代码：</p> <div class="language-python extra-class"><pre class="language-python"><code>
<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        output <span class="token operator">=</span> F<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output

<span class="token keyword">def</span> <span class="token function">train</span><span class="token punctuation">(</span>model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span><span class="token punctuation">:</span>
    model<span class="token punctuation">.</span>train<span class="token punctuation">(</span><span class="token punctuation">)</span>
    <span class="token keyword">for</span> batch_idx<span class="token punctuation">,</span> <span class="token punctuation">(</span>data<span class="token punctuation">,</span> target<span class="token punctuation">)</span> <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">:</span>
        data<span class="token punctuation">,</span> target <span class="token operator">=</span> data<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> target<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
        output <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> F<span class="token punctuation">.</span>nll_loss<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
        optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token keyword">if</span> batch_idx <span class="token operator">%</span> <span class="token number">10</span> <span class="token operator">==</span> <span class="token number">0</span><span class="token punctuation">:</span>
            <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
                epoch<span class="token punctuation">,</span> batch_idx <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">,</span>
                <span class="token number">100.</span> <span class="token operator">*</span> batch_idx <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    device <span class="token operator">=</span> torch<span class="token punctuation">.</span>device<span class="token punctuation">(</span><span class="token string">&quot;cuda&quot;</span> <span class="token keyword">if</span> torch<span class="token punctuation">.</span>cuda<span class="token punctuation">.</span>is_available<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">else</span> <span class="token string">&quot;cpu&quot;</span><span class="token punctuation">)</span>

    dataset1 <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span><span class="token string">'../data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    dataset2 <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span><span class="token string">'../data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset1<span class="token punctuation">)</span>
    test_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset2<span class="token punctuation">)</span>

    model <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
    optimizer <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adadelta<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>
    train<span class="token punctuation">(</span>model<span class="token punctuation">,</span> device<span class="token punctuation">,</span> train_loader<span class="token punctuation">,</span> optimizer<span class="token punctuation">,</span> epoch<span class="token punctuation">)</span>

    torch<span class="token punctuation">.</span>save<span class="token punctuation">(</span>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token string">&quot;mnist_cnn.pt&quot;</span><span class="token punctuation">)</span>

</code></pre></div><p>在这段代码中，我们首先定义了用于识别的模型<code>Net</code>，然后定义了训练的过程，在主函数中，我们首先初始化了数据集，之后便开始了训练。
可以看到，虽然只实现了这样一个简单的功能，但还是编写了不少代码，如下的代码其实完全是可以省略的。</p> <div class="language-python extra-class"><pre class="language-python"><code>    <span class="token comment"># 训练过程中必须的代码</span>
    optimizer<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>
    output <span class="token operator">=</span> model<span class="token punctuation">(</span>data<span class="token punctuation">)</span>
    loss <span class="token operator">=</span> F<span class="token punctuation">.</span>nll_loss<span class="token punctuation">(</span>output<span class="token punctuation">,</span> target<span class="token punctuation">)</span>
    loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>
    optimizer<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>

    <span class="token comment"># 让模型运行在不同设备上</span>
    model <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>

    <span class="token comment"># 记录一些训练指标</span>
    <span class="token keyword">print</span><span class="token punctuation">(</span><span class="token string">'Train Epoch: {} [{}/{} ({:.0f}%)]\tLoss: {:.6f}'</span><span class="token punctuation">.</span><span class="token builtin">format</span><span class="token punctuation">(</span>
        epoch<span class="token punctuation">,</span> batch_idx <span class="token operator">*</span> <span class="token builtin">len</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">.</span>dataset<span class="token punctuation">)</span><span class="token punctuation">,</span>
        <span class="token number">100.</span> <span class="token operator">*</span> batch_idx <span class="token operator">/</span> <span class="token builtin">len</span><span class="token punctuation">(</span>train_loader<span class="token punctuation">)</span><span class="token punctuation">,</span> loss<span class="token punctuation">.</span>item<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre></div><h1 id="使用pytorch-lightning来实现"><a href="#使用pytorch-lightning来实现" class="header-anchor">#</a> 使用Pytorch-Lightning来实现</h1> <p>使用Pytorch-Lightning其实就是将上述的代码中和模型相关的代码抽离出来，然后放到合适的位置就行了。直接放出代码：</p> <div class="language-python extra-class"><pre class="language-python"><code>
<span class="token keyword">class</span> <span class="token class-name">Net</span><span class="token punctuation">(</span>pl<span class="token punctuation">.</span>LightningModule<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>Net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">784</span><span class="token punctuation">,</span> <span class="token number">128</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>linear2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">128</span><span class="token punctuation">,</span> <span class="token number">10</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> x<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear1<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>linear2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        output <span class="token operator">=</span> F<span class="token punctuation">.</span>log_softmax<span class="token punctuation">(</span>x<span class="token punctuation">,</span> dim<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>
        <span class="token keyword">return</span> output

    <span class="token keyword">def</span> <span class="token function">training_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x<span class="token punctuation">,</span> y <span class="token operator">=</span> batch
        y_hat <span class="token operator">=</span> self<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        <span class="token keyword">return</span> loss

    <span class="token keyword">def</span> <span class="token function">test_step</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x<span class="token punctuation">,</span> y <span class="token operator">=</span> batch
        y_hat <span class="token operator">=</span> self<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> F<span class="token punctuation">.</span>cross_entropy<span class="token punctuation">(</span>y_hat<span class="token punctuation">,</span> y<span class="token punctuation">)</span>
        <span class="token keyword">return</span> loss
    
    <span class="token keyword">def</span> <span class="token function">configure_optimizers</span><span class="token punctuation">(</span>self<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token keyword">return</span> optim<span class="token punctuation">.</span>Adadelta<span class="token punctuation">(</span>self<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.01</span><span class="token punctuation">)</span>

<span class="token keyword">if</span> __name__ <span class="token operator">==</span> <span class="token string">'__main__'</span><span class="token punctuation">:</span>
    dataset1 <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span><span class="token string">'../data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> download<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
    dataset2 <span class="token operator">=</span> datasets<span class="token punctuation">.</span>MNIST<span class="token punctuation">(</span><span class="token string">'../data'</span><span class="token punctuation">,</span> train<span class="token operator">=</span><span class="token boolean">False</span><span class="token punctuation">)</span>
    train_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset1<span class="token punctuation">)</span>
    test_loader <span class="token operator">=</span> torch<span class="token punctuation">.</span>utils<span class="token punctuation">.</span>data<span class="token punctuation">.</span>DataLoader<span class="token punctuation">(</span>dataset2<span class="token punctuation">)</span>

    model <span class="token operator">=</span> Net<span class="token punctuation">(</span><span class="token punctuation">)</span>
    trainer <span class="token operator">=</span> pl<span class="token punctuation">.</span>Trainer<span class="token punctuation">(</span>gpus<span class="token operator">=</span><span class="token number">4</span><span class="token punctuation">)</span>
    trainer<span class="token punctuation">.</span>fit<span class="token punctuation">(</span>model<span class="token punctuation">,</span> train_loader<span class="token punctuation">)</span>
    trainer<span class="token punctuation">.</span>test<span class="token punctuation">(</span>model<span class="token punctuation">,</span> test_loader<span class="token punctuation">)</span>

</code></pre></div><p>容易看出，在Pytorch-Lightning中，在模型中新增了几个函数，来推动整个训练过程：</p> <ol><li><code>training_step</code> 用来定义模型的输出过程，该函数返回损失。</li> <li><code>test_step</code> 使用trainer.test()时调用。</li> <li><code>configure_optimizers</code> 用来定义模型用的优化器。</li></ol> <p>Pytorch-Lightning会在适当的时候，调用这些函数，以此来隐藏Pytorch中的工程代码，让开发者可以把更多的精力放在搭建复杂模型上。</p> <p>初了这两个函数之外，Pytorch-Lightning中还定义了这些函数：</p> <ol><li><code>validation_step</code> 与<code>training_step</code>类似，不过会在Validate的时候调用。</li> <li><code>prepare_data()</code> 用于准备数据。</li> <li><code>validation_epoch_end()</code> 在每一次Validation结束时调用。</li></ol> <h1 id="使用pytorch-lightning的好处"><a href="#使用pytorch-lightning的好处" class="header-anchor">#</a> 使用Pytorch-Lightning的好处</h1> <p>在上一节中，我们并没有明确地编写是否使用GPU、如何保存模型权重、如何记录训练中的产生的指标、训练进度的可视化、训练的版本管理等等，但在使用Pytorch-Lightning之后，我们可以以很低的成本做到这些。</p> <p>比如在终端里记录训练的进度以及其他指标，</p> <p><img src="/blog/assets/img/training_bar.f7e4463e.png" alt="Training Status"></p> <p>又比如每次训练的结果都可以保存下来，</p> <p><img src="/blog/assets/img/tensorboard.129fb2d7.png" alt="Versions"></p> <p>我在使用Pytorch-Lightning之后，感觉非常便利，可以把重心放在如何实现网络结构上，而不是如何将自己的代码工程化，一定程度上讲，简化了工作的流程。</p> <p>但如同其他封装好的库，Pytorch-Lightning隐藏了很多的细节，在一开始使用的时候，会不知道如何实现一些特定的功能，需要通过查看官方文档才能明白应该怎么写，而这在以前是相对容易的。但总体而言，使用Pytorch-Lightning是利大于弊的，强烈推荐大家可以尝试使用一下。</p> <p>这篇文章只是介绍了Pytorch-Lightning是什么以及它最简单的使用方法，在之后的文章里，还会介绍一些更深入的使用方法，让我们能够更好地掌控Pytorch-Lightning，实现更细粒度的功能，如果感兴趣的不妨关注一波。</p></div><footer><!----><hr><!----></footer></article><div class="sticker vuepress-toc"><div class="vuepress-toc-item vuepress-toc-h1 active"><a href="#什么是pytorch-lightning" title="什么是Pytorch-Lightning？">什么是Pytorch-Lightning？</a></div><div class="vuepress-toc-item vuepress-toc-h1"><a href="#pytorch识别mnist" title="Pytorch识别MNIST">Pytorch识别MNIST</a></div><div class="vuepress-toc-item vuepress-toc-h1"><a href="#使用pytorch-lightning来实现" title="使用Pytorch-Lightning来实现">使用Pytorch-Lightning来实现</a></div><div class="vuepress-toc-item vuepress-toc-h1"><a href="#使用pytorch-lightning的好处" title="使用Pytorch-Lightning的好处">使用Pytorch-Lightning的好处</a></div></div></div></div> <footer class="footer" data-v-3908d95c><div class="footer-left-wrap" data-v-3908d95c><ul class="contact" data-v-3908d95c><li class="contact-item" data-v-3908d95c><a href="https://git.mediosz.club/Tric" target="_blank" rel="noopener noreferrer" class="nav-link external" data-v-3908d95c><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-gitlab" data-v-3908d95c><path d="M22.65 14.39L12 22.13 1.35 14.39a.84.84 0 0 1-.3-.94l1.22-3.78 2.44-7.51A.42.42 0 0 1 4.82 2a.43.43 0 0 1 .58 0 .42.42 0 0 1 .11.18l2.44 7.49h8.1l2.44-7.51A.42.42 0 0 1 18.6 2a.43.43 0 0 1 .58 0 .42.42 0 0 1 .11.18l2.44 7.51L23 13.45a.84.84 0 0 1-.35.94z" data-v-3908d95c></path></svg>
          
        </a></li><li class="contact-item" data-v-3908d95c><a href="https://github.com/MediosZ" target="_blank" rel="noopener noreferrer" class="nav-link external" data-v-3908d95c><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-github" data-v-3908d95c><path d="M9 19c-5 1.5-5-2.5-7-3m14 6v-3.87a3.37 3.37 0 0 0-.94-2.61c3.14-.35 6.44-1.54 6.44-7A5.44 5.44 0 0 0 20 4.77 5.07 5.07 0 0 0 19.91 1S18.73.65 16 2.48a13.38 13.38 0 0 0-7 0C6.27.65 5.09 1 5.09 1A5.07 5.07 0 0 0 5 4.77a5.44 5.44 0 0 0-1.5 3.78c0 5.42 3.3 6.61 6.44 7A3.37 3.37 0 0 0 9 18.13V22" data-v-3908d95c></path></svg>
          
        </a></li><li class="contact-item" data-v-3908d95c><a href="mailto:mediosrity@qq.com" class="nav-link external" data-v-3908d95c><svg xmlns="http://www.w3.org/2000/svg" width="24" height="24" viewBox="0 0 24 24" fill="none" stroke="currentColor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round" class="feather feather-mail" data-v-3908d95c><path d="M4 4h16c1.1 0 2 .9 2 2v12c0 1.1-.9 2-2 2H4c-1.1 0-2-.9-2-2V6c0-1.1.9-2 2-2z" data-v-3908d95c></path><polyline points="22,6 12,13 2,6" data-v-3908d95c></polyline></svg>
          
        </a></li></ul></div> <div class="footer-right-wrap" data-v-3908d95c><ul class="copyright" data-v-3908d95c><li class="copyright-item" data-v-3908d95c><a href="http://www.beian.miit.gov.cn/" target="_blank" rel="noopener noreferrer" class="nav-link external" data-v-3908d95c>晋ICP备17009000</a></li></ul></div></footer></div><div class="global-ui"><!----><!----><!----></div></div>
    <script src="/blog/assets/js/app.bdc094dc.js" defer></script><script src="/blog/assets/js/6.e456ea1d.js" defer></script><script src="/blog/assets/js/3.78c3d3c8.js" defer></script><script src="/blog/assets/js/11.dd6dac4c.js" defer></script><script src="/blog/assets/js/10.70f7a74d.js" defer></script>
  </body>
</html>
